from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
from fastapi.middleware.cors import CORSMiddleware
import uvicorn
import ollama
from mcp import ClientSession
from mcp.client.sse import sse_client

# MCP æœåŠ¡å™¨åœ°å€
MCP_SERVER_URL = "http://localhost:8000/sse"
# Ollama æ¨¡å‹
OLLAMA_MODEL = 'qwen3:8b'

app = FastAPI(title="MCP Agent API")

# å…è®¸è·¨åŸŸ
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# å®šä¹‰è¯·æ±‚æ•°æ®æ¨¡å‹
class ChatRequest(BaseModel):
    prompt: str

async def chat_with_agent(user_prompt: str) -> str:
    """
    è¿æ¥ MCP æœåŠ¡å™¨ï¼Œåè°ƒ Ollamaï¼Œå¹¶è¿”å›æœ€ç»ˆç»“æœå­—ç¬¦ä¸²ã€‚
    """
    print(f"ğŸŒ‰ Agent: æ”¶åˆ°è¯·æ±‚ '{user_prompt}'ï¼Œæ­£åœ¨è¿æ¥ MCP: {MCP_SERVER_URL}...")
    
    try:
        # 1. å»ºç«‹ SSE è¿æ¥
        async with sse_client(MCP_SERVER_URL) as (read, write):
            async with ClientSession(read, write) as session:
                # 2. æ¡æ‰‹å¹¶è·å–å·¥å…·
                await session.initialize()
                tools_list = await session.list_tools()
                print(f"âœ… Agent: MCP è¿æ¥æˆåŠŸï¼Œè·å–åˆ°å·¥å…·: {[t.name for t in tools_list.tools]}")

                # 3. è½¬æ¢å·¥å…·æ ¼å¼
                ollama_tools = []
                for tool in tools_list.tools:
                    ollama_tools.append({
                        'type': 'function',
                        'function': {
                            'name': tool.name,
                            'description': tool.description,
                            'parameters': tool.inputSchema
                        }
                    })

                # 4. å¼€å§‹å¯¹è¯é€»è¾‘
                messages = [{'role': 'user', 'content': user_prompt}]

                response = ollama.chat(model=OLLAMA_MODEL, messages=messages, tools=ollama_tools)

                # æ£€æŸ¥æ˜¯å¦éœ€è¦è°ƒç”¨å·¥å…·
                if response['message'].get('tool_calls'):
                    print("ğŸ¤– Agent: AI å†³å®šè°ƒç”¨è¿œç¨‹å·¥å…·...")
                    
                    # å°† AI çš„å†³å®šåŠ å…¥å†å²
                    messages.append(response['message'])

                    for tool_call in response['message']['tool_calls']:
                        fn_name = tool_call['function']['name']
                        fn_args = tool_call['function']['arguments']
                        print(f"ğŸŒ Agent: å‘é€å·¥å…·è°ƒç”¨è¯·æ±‚ -> {fn_name}")

                        # é€šè¿‡ MCP åè®®è°ƒç”¨è¿œç¨‹å·¥å…·
                        result = await session.call_tool(fn_name, arguments=fn_args)
                        tool_output = result.content[0].text
                        print(f"ğŸ“© Agent: æ”¶åˆ°å·¥å…·ç»“æœ <- {tool_output}")

                        # å°†å·¥å…·ç»“æœåŠ å…¥å†å²
                        messages.append({'role': 'tool', 'content': tool_output})

                    # ç¬¬äºŒæ¬¡è¯¢é—® Ollamaï¼Œè·å–æœ€ç»ˆå›ç­”
                    final_response = ollama.chat(model=OLLAMA_MODEL, messages=messages)
                    return final_response['message']['content']
                else:
                    # ä¸éœ€è¦å·¥å…·ï¼Œç›´æ¥è¿”å›å›ç­”
                    return response['message']['content']

    except Exception as e:
        print(f"âŒ Agent Error: {e}")
        raise e

# å®šä¹‰ API æ¥å£
@app.post("/agent/chat")
async def chat_endpoint(request: ChatRequest):
    try:
        ai_response = await chat_with_agent(request.prompt)
        return {"response": ai_response}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

if __name__ == "__main__":
    # æ³¨æ„ç›‘å¬ 8001 ç«¯å£ï¼Œé¿å…å’Œ MCP Server (8000) å†²çª
    print("ğŸš€ Agent æ­£åœ¨å¯åŠ¨ï¼Œç›‘å¬ç«¯å£ 8001...")
    uvicorn.run(app, host="0.0.0.0", port=8001)